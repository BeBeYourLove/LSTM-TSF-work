import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
import time
import seaborn as sns
import math, time
from sklearn.metrics import mean_squared_error
import plotly.express as px
import plotly.graph_objects as go
from statsmodels.tsa.stattools import adfuller

data = pd.read_csv('BTC-USD(2019_8_1~2020_8_1).csv')
data = data.sort_values('Date')

# plt.figure(figsize=(15, 9))
# plt.plot(data[['Close']])
# plt.xticks(range(0, data.shape[0], 20), data['Date'].loc[::20], rotation=45)
# plt.title("Stock Price", fontsize=18, fontweight='bold')
# plt.xlabel('Date', fontsize=18)
# plt.ylabel('Close Price (USD)', fontsize=18)
# plt.show()

clo = data[['Close']].diff().dropna()

# 特征缩放
scaler = MinMaxScaler(feature_range=(-1, 1))
close = scaler.fit_transform(clo.values.reshape(-1, 1))
price = pd.DataFrame(close)


'''制作训练的数据集'''
def split_data(stock, lookback):
    data_raw = stock.to_numpy()
    data = []

    # 进行数据的划分
    for index in range(len(data_raw)-lookback):
        data.append(data_raw[index:index+lookback])

    data = np.array(data)
    test_set_size = int(np.round(0.2*data.shape[0]))
    train_set_size = data.shape[0]-test_set_size

    x_train = data[:train_set_size, :-1, :]
    y_train = data[:train_set_size, -1, :]

    x_test = data[train_set_size:, :-1, :]
    y_test = data[train_set_size:, -1, :]

    return x_train, y_train, x_test, y_test

lookback = 20
x_train, y_train, x_test, y_test = split_data(price, lookback)
# print('x_train.shape:', x_train.shape)
# print('y_train.shape:', y_train.shape)
# print('x_test.shape:', x_test.shape)
# print('y_test.shape:', y_test.shape)

# 序列平稳性检测函数
def test_stationarity(timeseries):
    rolmean = timeseries.rolling(20).mean()
    rolstd = timeseries.rolling(20).std()

    orig = plt.plot(timeseries, color='blue', label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label='Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.xticks(range(0, timeseries.shape[0], 20), data.index[::20], rotation=45)

    print('Result of Dickey-Fuller Test:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['adf', 'pvalue', 'usedlag', 'nobs'])
    for key, value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print(dfoutput)


# 构建LSTM模型
x_train = torch.from_numpy(x_train).type(torch.Tensor)
x_test = torch.from_numpy(x_test).type(torch.Tensor)
y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)
y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)
y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)
y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)

input_dim = 1
hidden_dim = 32
num_layers = 2
output_dim = 1
epochs = 100
dropout = 0.2

class LSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout):
        super(LSTM, self).__init__()
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()
        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
        # print("hn的shape:", hn.shape)
        # print("cn的shape:", cn.shape)
        # print("out的shape:", out.shape)
        out = self.fc(out[:, -1, :])
        return out

model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=output_dim, dropout=dropout)
criterion = torch.nn.MSELoss()
optimiser = torch.optim.Adam(model.parameters(), lr=0.01)


hist = np.zeros(epochs)
start_time = time.time()
lstm = []

for t in range(epochs):
    y_train_pred = model(x_train)

    loss = criterion(y_train_pred, y_train_lstm)
    print("Epoch", t, "MSELoss", loss.item())
    hist[t] = loss.item()

    optimiser.zero_grad()
    loss.backward()
    optimiser.step()

training_time = time.time() - start_time
print("Training time: {}".format(training_time))

y_train_pred_inv = scaler.inverse_transform(y_train_pred.detach().numpy())
y_train_lstm_inv = scaler.inverse_transform(y_train_lstm.detach().numpy())

y_label = np.expand_dims(data['Close'], 1)

y_train_pred_inv += y_label[20:297]
y_train_lstm_inv += y_label[20:297]

predict = pd.DataFrame(y_train_pred_inv)
original = pd.DataFrame(y_train_lstm_inv)

fig = plt.figure()
fig.subplots_adjust(hspace=0.2, wspace=0.2)

plt.subplot(1, 2, 1)
ax = sns.lineplot(x=original.index, y=original[0], label="Data", color='royalblue')
ax = sns.lineplot(x=predict.index, y=predict[0], label="Training Prediction (LSTM)", color='tomato')
ax.set_title('Stock price', size=14, fontweight='bold')
ax.set_xlabel('Days', size=14)
ax.set_ylabel('Cost (USD)', size=14)
ax.set_xticklabels('', size=10)

plt.subplot(1, 2, 2)
ax = sns.lineplot(data=hist, color='royalblue')
ax.set_xlabel("Epoch", size=14)
ax.set_ylabel("Loss", size=14)
ax.set_title("Training Loss", size=14, fontweight='bold')
fig.set_figheight(6)
fig.set_figwidth(16)

plt.show()

# y_test_pred = model(x_test)
# print("x_test:", x_test.shape)
# print("y_test_pred:", y_test_pred.shape)
#
# y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())
# print(y_train_pred.shape)
# y_train = scaler.inverse_transform(y_train_lstm.detach().numpy())
# print(y_train.shape)
# y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())
# y_test = scaler.inverse_transform(y_test_lstm.detach().numpy())
#
# trainScore = math.sqrt(mean_squared_error(y_train[:, 0], y_train_pred[:, 0]))
# print('Train Score: %.2f RMSE' % (trainScore))
# testScore = math.sqrt(mean_squared_error(y_test[:, 0], y_test_pred[:, 0]))
# print('Test Score: %.2f RMSE' % (testScore))
# lstm.append(trainScore)
# lstm.append(testScore)
# lstm.append(training_time)
#
# trainPredictPlot = np.empty_like(price)
# trainPredictPlot[:, :] = np.nan
# trainPredictPlot[lookback:len(y_train_pred)+lookback, :] = y_train_pred
#
# testPredictPlot = np.empty_like(price)
# testPredictPlot[:, :] = np.nan
# testPredictPlot[len(y_train_pred)+lookback-1:len(price)-1, :] = y_test_pred
#
# original = scaler.inverse_transform(price.values.reshape(-1, 1))
#
# predictions = np.append(trainPredictPlot, testPredictPlot, axis=1)
# predictions = np.append(predictions, original, axis=1)
# result = pd.DataFrame(predictions)
#
# fig = go.Figure()
# fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[0], mode='lines', name='Train prediction')))
# fig.add_trace(go.Scatter(x=result.index, y=result[1], mode='lines', name='Test prediction'))
# fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[2], mode='lines', name='Actual Value')))
#
# fig.update_layout(
#     xaxis=dict(
#         showline=True,
#         showgrid=True,
#         showticklabels=False,
#         linecolor='white',
#         linewidth=2
#     ),
#     yaxis=dict(
#         title_text='Close (USD)',
#         titlefont=dict(
#             family='Rockwell',
#             size=12,
#             color='white'
#         ),
#         showline=True,
#         showgrid=True,
#         showticklabels=True,
#         linecolor='white',
#         linewidth=2,
#         ticks='outside',
#         tickfont=dict(
#             family='Rockwell',
#             size=12,
#             color='white'
#         ),
#     ),
#     showlegend=True,
#     template='plotly_dark'
# )
#
# annotations=[]
# annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,
#                         xanchor='left', yanchor='bottom',
#                         text='Results (LSTM)', font=dict(family='Rockwell', size=26, color='white'), showarrow=False))
# fig.update_layout(annotations=annotations)
# fig.show()
